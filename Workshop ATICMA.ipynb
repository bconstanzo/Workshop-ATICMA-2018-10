{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción al Machine Learning con Python\n",
    "## Ejercicio: Reuters Dataset\n",
    "\n",
    "Para este ejemplo vamos a utilizar NumPy, matplotlib y keras. Todos estos ya se encuentran disponibles en Google Colaboratory, asique no es necesario instalar nada.\n",
    "\n",
    "Si quieren seguir el ejemplo de manera local en sus computadoras, les recomendamos utilizar la distribución [Anaconda](https://www.anaconda.com/) como su entorno de Python, para minimizar las complicaciones con la instalación de los paquetes.\n",
    "\n",
    "Este ejercicio está basado en notebooks de François Chollet disponible en https://github.com/fchollet/deep-learning-with-python-notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 2246)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset reuters consiste en un poco más de 11,000 cables de noticias de la agencia de noticias Reuters. Está codificado de manera que cada palabra ha sido reemplazada por un número. Por como cargamos los datos, vamos a manejar un vocabulario compuesto por las 10,000 palabras más comunes, y las palabras que no entren en esta categoría van a ser representadas por un número particular que indica \"palabra desconocida\".\n",
    "\n",
    "Si queremos leer los cables, es necesario traducirlos de vuelta a palabras. Esto se puede hacer mediante el indice de palabras del dataset, y definiendo una función que lo recorra de manera inversa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for key, value in word_index.items()])\n",
    "\n",
    "def decode_newswire(nw):\n",
    "    return \" \".join(reverse_word_index.get(i - 3, \"?\") for i in nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_newswire(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los datos, es necesario codificarlos de manera adecuada para que la red neuronal los pueda trabajar. Una de las formas de hacer esto es definiendo dos funciones, una para vectorizar los datos de entrada, y otra para codificar la categoría de cada cable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `vectorize_sequences` se usa para codificar el texto de los cables mediante una representación conocida como _bag of words_. Cada vector resultante tiene 10,000 elementos, con valor 0 o 1 y de esta manera se indica la presencia de una palabra en el cable.\n",
    "\n",
    "La función `to_one_hot` se ocupa de codificar las etiquetas, y genera un vector de 46 elementos donde todos tienen valor 0, excepto la categoría a la cual corresponde la noticia del cable. La función to_one_hot es equivalente a `keras.utils.to_categorical`.\n",
    "\n",
    "Una vez definidas estas funciones, debemos convertir los datos a estas representaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "y_train = to_one_hot(train_labels)\n",
    "y_test = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
